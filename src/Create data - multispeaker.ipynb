{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VvOVvWY1G4JL"
   },
   "source": [
    "###### La seguente implementazione seguirà quanto scritto nei paper:\n",
    "\"We train on the first 99 VCTK speakers and test on the 8 remaining ones\" (in realtà sono 9 nel validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gAnlZTfG4JM"
   },
   "source": [
    "Visto che faremo fine-tuning sul task di single speaker, è importante sottolineare un aspetto. Il primo speaker (quello che serve nel task di single speaker), non può avere i dati del validation (nel task di single speaker) nel training del primo allenamento. Perciò, in questo notebook, si dovrà implementare un modo affinchè il validation del task di single speaker sia un'intersezione nulla con il training del task di multiple-speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20767,
     "status": "ok",
     "timestamp": 1609614797275,
     "user": {
      "displayName": "Giorgio Bini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ7Iaq18IIOku9A5VZf1pMFRhT9LBW90kGCpzqsg=s64",
      "userId": "09218258456109657564"
     },
     "user_tz": -60
    },
    "id": "JzanBX3PNkWo",
    "outputId": "d244cc5c-df97-425c-bf0e-3ca80208203e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n",
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "gdrive = True\n",
    "import sys\n",
    "if gdrive:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    %tensorflow_version 1.x\n",
    "    sys.path.append('/content/gdrive/My Drive/Tesi/src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30109,
     "status": "ok",
     "timestamp": 1609614806628,
     "user": {
      "displayName": "Giorgio Bini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ7Iaq18IIOku9A5VZf1pMFRhT9LBW90kGCpzqsg=s64",
      "userId": "09218258456109657564"
     },
     "user_tz": -60
    },
    "id": "oWJE2v4SNT9O",
    "outputId": "faaa4898-aacd-45d1-a82e-8c4fdc03cbd2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import os, argparse\n",
    "import numpy as np\n",
    "import time\n",
    "import h5py\n",
    "import pickle\n",
    "import librosa\n",
    "from scipy import interpolate\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import decimate, butter, lfilter\n",
    "import IPython.display as ipd\n",
    "from scipy import signal\n",
    "from ops import silence_filtering, upsample\n",
    "from tqdm.notebook import tqdm\n",
    "from keras.applications import MobileNet\n",
    "from keras.models import Model\n",
    "import re\n",
    "from skimage.transform import resize\n",
    "import librosa\n",
    "from random import sample\n",
    "import random\n",
    "from dataset import DataSet\n",
    "from training_ops import read_hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EA0YkG0G4JN"
   },
   "outputs": [],
   "source": [
    "dimension = 8192 #--dimension -> dimension of patches --use -1 for no patching\n",
    "sr = 16000 #args.sr -> audio sampling rate\n",
    "scale = 4 #args.scale -> scaling factor\n",
    "low_pass = True #args.low_pass -> apply low-pass filter when generating low-res patches\n",
    "stride = 2048  #args.stride -> 8192*0.75 = 2048 (Time Frequency Networks For Audio Super-Resolu)\n",
    "batch_size = 128 # sia tfnet che kuleshov usano 128\n",
    "trim_silence = True\n",
    "silence_trash = 0 #DA DEFINIRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQNjJlxAG4JN"
   },
   "outputs": [],
   "source": [
    "def silence_filtering(sig, rmsenergy_treshold = 0.05, prob = 0.1):\n",
    "    rmse = librosa.feature.rmse(y=sig, frame_length=256, hop_length=128)\n",
    "    top_db = librosa.power_to_db(np.array([rmsenergy_treshold]), ref=np.max(rmse.squeeze()))\n",
    "    filt_sig = librosa.effects.split(sig, top_db=-top_db, frame_length=256, hop_length=128)\n",
    "    try:\n",
    "        non_mute = sig[filt_sig[0][0]:filt_sig[len(filt_sig)-1][1]]\n",
    "        if filt_sig[0][0] > 0: #if there is mute at the beginnig, I think it happen always\n",
    "            mute_section_idx = np.array([0, filt_sig[0][0]])\n",
    "            #with a probability = prob keep the silent part at the beginning\n",
    "            mute = sig[mute_section_idx[0]:mute_section_idx[1]]\n",
    "            v = random.uniform(0, 1)\n",
    "            if v<= prob:\n",
    "                out = np.concatenate([mute, non_mute])\n",
    "            else:\n",
    "                out = non_mute\n",
    "        else:\n",
    "            out = non_mute\n",
    "    except:\n",
    "        out = sig\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RkujwZQ8G4JO"
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.dirname(os.path.abspath('.'))\n",
    "out = os.path.join(ROOT_DIR, 'processedData', 'multispeaker', 'train&validation' + '\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u9yPCtAaG4JO"
   },
   "outputs": [],
   "source": [
    "speaker1_id = 'p225'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6K4jFSMG4JO"
   },
   "outputs": [],
   "source": [
    "def from_txt_to_list(txt):\n",
    "    out_list = []\n",
    "    with open(txt) as f:\n",
    "        for line in f:\n",
    "            out_list.append(line.strip())\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ho97aAyG4JO"
   },
   "outputs": [],
   "source": [
    "def create_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5NfNAjWmG4JP"
   },
   "outputs": [],
   "source": [
    "def create_data(how = 'training'): \n",
    "    txtfiles_dir = os.path.join(ROOT_DIR, 'processedData', 'txtfiles')\n",
    "    if how == 'training':\n",
    "        tr = True\n",
    "        txt_list = os.path.join(txtfiles_dir, '{}-speakers-sampled.txt'.format('train'))\n",
    "        speaker1_txt = os.path.join(txtfiles_dir, 'speaker1-{}-files.txt'.format('train'))\n",
    "        fold1 = 'train' \n",
    "    elif how == 'validation':\n",
    "        tr = False\n",
    "        txt_list = os.path.join(txtfiles_dir, '{}-speakers-sampled.txt'.format('val'))\n",
    "        speaker1_txt = os.path.join(txtfiles_dir, 'speaker1-{}-files.txt'.format('val'))\n",
    "        fold1 = 'validation' \n",
    "    elif how == 'test':\n",
    "        tr = False\n",
    "        txt_list = os.path.join(txtfiles_dir, '{}-speakers.txt'.format('test'))\n",
    "        speaker1_txt = os.path.join(txtfiles_dir, 'speaker1-{}-files.txt'.format('val'))\n",
    "        fold1 = 'test' \n",
    "    else:\n",
    "        raise ValueError('you should choose between training, validation or test')\n",
    "        return None #necessario?\n",
    "    \n",
    "    id_list = from_txt_to_list(txt_list)\n",
    "    speaker1_list = from_txt_to_list(speaker1_txt)\n",
    "    file_list = []\n",
    "    ID_list = []\n",
    "    file_extensions = set(['.wav'])\n",
    "    data_path = os.path.join(ROOT_DIR, 'rawData', 'VCTK-Corpus', 'wav48')\n",
    "    for speaker_id in id_list:\n",
    "        data_dir = os.path.join(data_path, speaker_id)\n",
    "        for file in os.listdir(data_dir):\n",
    "            filename = file.strip()\n",
    "            ext = os.path.splitext(filename)[1]\n",
    "            if (speaker_id == speaker1_id)&(filename not in speaker1_list):\n",
    "                pass\n",
    "            else:\n",
    "                if ext in file_extensions:\n",
    "                    file_list.append(os.path.join(data_dir, filename))\n",
    "    \n",
    "    h5_file = h5py.File(out + '{}_data.hdf5'.format(fold1), 'w')\n",
    "    num_files = len(file_list)\n",
    "    # patches to extract and their size\n",
    "    d, d_lr = dimension, dimension\n",
    "    s, s_lr = stride, stride\n",
    "    hr_patches, lr_patches = list(), list()\n",
    "    num_patches = 0\n",
    "    file_name_diz = {}\n",
    "    \n",
    "    for j, file_path in enumerate(tqdm(file_list)):\n",
    "        ID = int(re.search('p\\d\\d\\d', file_path).group(0)[1:]) #originariamente era int(re.search('p\\d\\d\\d/', file_path).group(0)[1:-1])\n",
    "        # L'impostazione originale aveva due problemi. La regex ritornava un NoneType object, perciò è stato rimosso il backslash finale. \n",
    "        # Inoltre per ricavare l'ID dello speacker (es. p255 -> ID = 255), originariamente si aveva .group(0)[1:-1]. Tuttavia in quel caso veniva ID = 22 e non 225    \n",
    "\n",
    "        # load audio file\n",
    "        x, fs = librosa.load(file_path, sr=sr)\n",
    "        \n",
    "        if ((how == 'training')&(trim_silence == True)):\n",
    "            x = silence_filtering(x, rmsenergy_treshold = 0.05, prob = 0.4)           \n",
    "        \n",
    "        # crop so that it works with scaling ratio\n",
    "        x_len = len(x)\n",
    "        x = x[ : x_len - (x_len % scale)] #sostanzialmente questa operazione permette di ottenere una lunghezza di x (numero di campioni) adeguata allo scaling ratio.\n",
    "        # Es: scale = 2 -> se il numero di campioni (lunghezza di x) è pari, allora non succede nulla. Se è dispari, invece, l'ultimo campione viene rimosso. \n",
    "\n",
    "        # generate low-res version\n",
    "        if low_pass:\n",
    "            x_lr = decimate(x, scale)\n",
    "        else:\n",
    "            x_lr = np.array(x[0::scale]) # la lunghezza è pari a x/scale (approssimazione per eccesso). \n",
    "                                         # Sostanzialmente in questo modo si prendono campioni a salti. \n",
    "                                         # Es. a = np.arange(5)\n",
    "                                         #     a[0::2] -> array([0, 2, 4])\n",
    "        x_lr = upsample(x_lr, scale) #interpolate low-res patches with cubic splines. \n",
    "                                     #After this line of code len(x_lr) is equal to len(x)\n",
    "        assert len(x) % scale == 0\n",
    "        assert len(x_lr) == len(x)\n",
    "        assert x.dtype == np.float32\n",
    "        assert x_lr.dtype == np.float32\n",
    "\n",
    "        # generate patches\n",
    "        max_i = len(x) - d + 1\n",
    "        n_patch_of_file = 0\n",
    "        for i in range(0, max_i, s):\n",
    "            i_lr = i\n",
    "            hr_patch = np.array( x[i : i+d] )\n",
    "            lr_patch = np.array( x_lr[i_lr : i_lr+d_lr] )\n",
    "\n",
    "            assert len(hr_patch) == d\n",
    "            assert len(lr_patch) == d_lr\n",
    "\n",
    "            hr_patches.append(hr_patch.reshape((d,1)))\n",
    "            lr_patches.append(lr_patch.reshape((d_lr,1)))\n",
    "            ID_list.append(ID)\n",
    "            \n",
    "    num_patches = len(hr_patches)\n",
    "    num_to_keep = int(np.floor(num_patches / batch_size) * batch_size)\n",
    "    hr_patches = np.array(hr_patches[:num_to_keep])\n",
    "    lr_patches = np.array(lr_patches[:num_to_keep])\n",
    "    ID_list = ID_list[:num_to_keep]\n",
    "    \n",
    "    data_set_lr = h5_file.create_dataset('data_lr', lr_patches.shape, np.float32)\n",
    "    data_set_lr[...] = lr_patches\n",
    "    label_set = h5_file.create_dataset('label', hr_patches.shape, np.float32)\n",
    "    label_set[...] = hr_patches\n",
    "    \n",
    "    file = open(out + 'ID_list_patches_' + str(d) + '_' + str(scale), 'wb')\n",
    "    pickle.dump(ID_list, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "d10f3f2711f643c6a371559b7689479f"
     ]
    },
    "id": "LkVqNdE_G4JP",
    "outputId": "90d86098-3983-4ed0-d769-81bf3fd5c61b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10f3f2711f643c6a371559b7689479f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15758.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 83.93202962080638 minutes ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "create_data(how = 'training')\n",
    "print(\"--- %s minutes ---\" % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVsFIAOYRsVC"
   },
   "source": [
    "### Sampling \n",
    "Potrebbe esserci un po di disordine nell'ordine delle celle. L'importnate è capire che nel training campiono 128896 patch e nel validation 30848"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 864,
     "status": "ok",
     "timestamp": 1609614896498,
     "user": {
      "displayName": "Giorgio Bini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ7Iaq18IIOku9A5VZf1pMFRhT9LBW90kGCpzqsg=s64",
      "userId": "09218258456109657564"
     },
     "user_tz": -60
    },
    "id": "dzF3y5K1IZkO"
   },
   "outputs": [],
   "source": [
    "def sample_from_multidimensional_array(X, Y, how_many):\n",
    "    n = X.shape[0]\n",
    "    idx_tot = np.arange(n)\n",
    "    idx_to_sample = np.random.choice(idx_tot, how_many, replace = False)\n",
    "    return X[idx_to_sample, :, :], Y[idx_to_sample, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1056,
     "status": "ok",
     "timestamp": 1609614897859,
     "user": {
      "displayName": "Giorgio Bini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ7Iaq18IIOku9A5VZf1pMFRhT9LBW90kGCpzqsg=s64",
      "userId": "09218258456109657564"
     },
     "user_tz": -60
    },
    "id": "hCu6LPUvJBTE"
   },
   "outputs": [],
   "source": [
    "out = '/content/gdrive/My Drive/Tesi/processedData/multispeaker/train&validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83023,
     "status": "ok",
     "timestamp": 1609614984451,
     "user": {
      "displayName": "Giorgio Bini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ7Iaq18IIOku9A5VZf1pMFRhT9LBW90kGCpzqsg=s64",
      "userId": "09218258456109657564"
     },
     "user_tz": -60
    },
    "id": "VIBtwh77QXgL",
    "outputId": "4b4bb9ae-3fb7-49a7-9528-637fea86cd77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.85 s, sys: 10.5 s, total: 12.3 s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hf = h5py.File(out + 'train_data.hdf5', 'r')\n",
    "X_tr, Y_tr = np.array(hf.get('data_lr')), np.array(hf.get('label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9134,
     "status": "ok",
     "timestamp": 1609615307125,
     "user": {
      "displayName": "Giorgio Bini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ7Iaq18IIOku9A5VZf1pMFRhT9LBW90kGCpzqsg=s64",
      "userId": "09218258456109657564"
     },
     "user_tz": -60
    },
    "id": "-KvTwxCVIbNI",
    "outputId": "2d7899dd-3a63-4ce9-876a-3f6899005dcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.13 s, sys: 7.22 s, total: 8.35 s\n",
      "Wall time: 8.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "how_many = 128896\n",
    "if X_tr.shape[0]>how_many:\n",
    "    X_tr, Y_tr = sample_from_multidimensional_array(X_tr, Y_tr, how_many = how_many)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5969,
     "status": "ok",
     "timestamp": 1609615307127,
     "user": {
      "displayName": "Giorgio Bini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ7Iaq18IIOku9A5VZf1pMFRhT9LBW90kGCpzqsg=s64",
      "userId": "09218258456109657564"
     },
     "user_tz": -60
    },
    "id": "doPiUNY4G4JS",
    "outputId": "9bbe7bdc-ef66-49d4-9105-2515612a0c25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128896, 8192, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_tr.shape)\n",
    "assert (X_tr.shape[0] == how_many)\n",
    "assert (X_tr.shape[0] % 128) == 0\n",
    "assert (X_tr.shape[0] == Y_tr.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64464,
     "status": "ok",
     "timestamp": 1609615366970,
     "user": {
      "displayName": "Giorgio Bini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ7Iaq18IIOku9A5VZf1pMFRhT9LBW90kGCpzqsg=s64",
      "userId": "09218258456109657564"
     },
     "user_tz": -60
    },
    "id": "InQUJPS3PZsL",
    "outputId": "c3b65eaf-c1f9-444f-dade-5651ebd2526c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 209 ms, sys: 5.77 s, total: 5.98 s\n",
      "Wall time: 59.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "h5_file = h5py.File(out + 'train_data_s.hdf5', 'w')\n",
    "data_set_lr = h5_file.create_dataset('data_lr', X_tr.shape, np.float32)\n",
    "data_set_lr[...] = X_tr\n",
    "label_set = h5_file.create_dataset('label', X_tr.shape, np.float32)\n",
    "label_set[...] = Y_tr\n",
    "h5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82,
     "referenced_widgets": [
      "28a9f4a9441d43e39b0d17e982098c99",
      "2c3f17f6d6fd493f97e4d70dc2b454cc",
      "5f45b431362c4110bda40d104911010d",
      "66de46012a874a2b91f2a51030e271c5",
      "cb50169f28ef48299e1adfa7857a34b3",
      "e70dbb57f4e84c789507fe1cec23377e",
      "6d05226406e04aa5aa909fa2e2cfca79",
      "188ebcbc74594da98c089c5af5f5f1fb"
     ]
    },
    "id": "Xok03ZY7G4JS",
    "outputId": "0476e0af-fe2c-4bf2-9cfa-5244d0c61495"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a9f4a9441d43e39b0d17e982098c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1032.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training_data = DataSet(X_tr, Y_tr, epochs_completed = 0)\n",
    "for i in tqdm(range(int(X_tr.shape[0]/128))):\n",
    "    training_data.next_batch(128)\n",
    "print(training_data.epochs_completed)\n",
    "training_data.next_batch(128)\n",
    "print(training_data.epochs_completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 89618,
     "status": "ok",
     "timestamp": 1609615074102,
     "user": {
      "displayName": "Giorgio Bini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ7Iaq18IIOku9A5VZf1pMFRhT9LBW90kGCpzqsg=s64",
      "userId": "09218258456109657564"
     },
     "user_tz": -60
    },
    "id": "joIabdNJSuaA"
   },
   "outputs": [],
   "source": [
    "out = '/content/gdrive/My Drive/Tesi/processedData/multispeaker/train&validation/'\n",
    "hf_val = h5py.File(out + 'validation_data.hdf5', 'r')\n",
    "X_val = np.array(hf_val.get('data_lr'))\n",
    "Y_val = np.array(hf_val.get('label'))\n",
    "how_many_val = 30848\n",
    "if X_val.shape[0]>how_many_val:\n",
    "    X_val, Y_val = sample_from_multidimensional_array(X_val, Y_val, how_many = how_many_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 89613,
     "status": "ok",
     "timestamp": 1609615074104,
     "user": {
      "displayName": "Giorgio Bini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ7Iaq18IIOku9A5VZf1pMFRhT9LBW90kGCpzqsg=s64",
      "userId": "09218258456109657564"
     },
     "user_tz": -60
    },
    "id": "kPDvUiIJG4JT",
    "outputId": "151086d6-45b2-4924-9c06-0905615f615c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30848, 8192, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_val.shape)\n",
    "assert (X_val.shape[0] % 128) == 0\n",
    "assert (X_val.shape[0] == Y_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 104043,
     "status": "ok",
     "timestamp": 1609615088537,
     "user": {
      "displayName": "Giorgio Bini",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJ7Iaq18IIOku9A5VZf1pMFRhT9LBW90kGCpzqsg=s64",
      "userId": "09218258456109657564"
     },
     "user_tz": -60
    },
    "id": "n6_Ds4R3TNaz"
   },
   "outputs": [],
   "source": [
    "h5_file = h5py.File(out + 'validation_data_s.hdf5', 'w')\n",
    "data_set_lr = h5_file.create_dataset('data_lr', X_val.shape, np.float32)\n",
    "data_set_lr[...] = X_val\n",
    "label_set = h5_file.create_dataset('label', X_val.shape, np.float32)\n",
    "label_set[...] = Y_val\n",
    "h5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zPSMZtDcG4JU",
    "outputId": "236f6e18-25fe-4a61-ac3e-6eb58403d2e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "validation_data = DataSet(X_val, Y_val, epochs_completed = 0)\n",
    "for i in range(int(X_val.shape[0]/128)):\n",
    "    validation_data.next_batch(128)\n",
    "print(validation_data.epochs_completed)\n",
    "validation_data.next_batch(128)\n",
    "print(validation_data.epochs_completed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dksIAU5IG4JU"
   },
   "source": [
    "### Fold Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rYNl5kgyG4JU"
   },
   "outputs": [],
   "source": [
    "def create_data_in_folders(how = 'training'): \n",
    "    txtfiles_dir = os.path.join(ROOT_DIR, 'processedData', 'txtfiles')\n",
    "    if how == 'training':\n",
    "        tr = True\n",
    "        txt_list = os.path.join(txtfiles_dir, '{}-speakers.txt'.format('train'))\n",
    "        speaker1_txt = os.path.join(txtfiles_dir, 'speaker1-{}-files.txt'.format('train'))\n",
    "        fold1 = 'train' \n",
    "    elif how == 'validation':\n",
    "        tr = False\n",
    "        txt_list = os.path.join(txtfiles_dir, '{}-speakers.txt'.format('val'))\n",
    "        speaker1_txt = os.path.join(txtfiles_dir, 'speaker1-{}-files.txt'.format('val'))\n",
    "        fold1 = 'validation' \n",
    "    elif how == 'test':\n",
    "        tr = False\n",
    "        txt_list = os.path.join(txtfiles_dir, '{}-speakers.txt'.format('test'))\n",
    "        speaker1_txt = os.path.join(txtfiles_dir, 'speaker1-{}-files.txt'.format('val'))\n",
    "        fold1 = 'test' \n",
    "    else:\n",
    "        raise ValueError('you should choose between training, validation or test')\n",
    "        return None #necessario?\n",
    "    \n",
    "    id_list = from_txt_to_list(txt_list)\n",
    "    speaker1_list = from_txt_to_list(speaker1_txt)\n",
    "    file_list = []\n",
    "    ID_list = []\n",
    "    file_extensions = set(['.wav'])\n",
    "    data_path = os.path.join(ROOT_DIR, 'rawData', 'VCTK-Corpus', 'wav48')\n",
    "    for speaker_id in id_list:\n",
    "        data_dir = os.path.join(data_path, speaker_id)\n",
    "        for file in os.listdir(data_dir):\n",
    "            filename = file.strip()\n",
    "            ext = os.path.splitext(filename)[1]\n",
    "            if (speaker_id == speaker1_id)&(filename not in speaker1_list):\n",
    "                pass\n",
    "            else:\n",
    "                if ext in file_extensions:\n",
    "                    file_list.append(os.path.join(data_dir, filename))\n",
    "    \n",
    "    out_dir = os.path.join(out, fold1, '')\n",
    "    nested_out_dir_index = 1\n",
    "    nested_out_dir = os.path.join(out_dir, str(nested_out_dir_index), '')\n",
    "    create_dir(nested_out_dir)\n",
    "    n_files_in_nested_out_dir = 0\n",
    "    num_files = len(file_list)\n",
    "    # patches to extract and their size\n",
    "    d, d_lr = dimension, dimension\n",
    "    s, s_lr = stride, stride\n",
    "    num_patches = 0\n",
    "    file_name_diz = {}\n",
    "    \n",
    "    for j, file_path in enumerate(tqdm(file_list)):\n",
    "        ID = int(re.search('p\\d\\d\\d', file_path).group(0)[1:]) #originariamente era int(re.search('p\\d\\d\\d/', file_path).group(0)[1:-1])\n",
    "        # L'impostazione originale aveva due problemi. La regex ritornava un NoneType object, perciò è stato rimosso il backslash finale. \n",
    "        # Inoltre per ricavare l'ID dello speacker (es. p255 -> ID = 255), originariamente si aveva .group(0)[1:-1]. Tuttavia in quel caso veniva ID = 22 e non 225    \n",
    "\n",
    "        # load audio file\n",
    "        x, fs = librosa.load(file_path, sr=sr)\n",
    "        \n",
    "        if ((how == 'training')&(trim_silence == True)):\n",
    "            x = silence_filtering(x, rmsenergy_treshold = 0.05, prob = 0.1)           \n",
    "        \n",
    "        # crop so that it works with scaling ratio\n",
    "        x_len = len(x)\n",
    "        x = x[ : x_len - (x_len % scale)] #sostanzialmente questa operazione permette di ottenere una lunghezza di x (numero di campioni) adeguata allo scaling ratio.\n",
    "        # Es: scale = 2 -> se il numero di campioni (lunghezza di x) è pari, allora non succede nulla. Se è dispari, invece, l'ultimo campione viene rimosso. \n",
    "\n",
    "        # generate low-res version\n",
    "        if low_pass:\n",
    "            x_lr = decimate(x, scale)\n",
    "        else:\n",
    "            x_lr = np.array(x[0::scale]) # la lunghezza è pari a x/scale (approssimazione per eccesso). \n",
    "                                         # Sostanzialmente in questo modo si prendono campioni a salti. \n",
    "                                         # Es. a = np.arange(5)\n",
    "                                         #     a[0::2] -> array([0, 2, 4])\n",
    "        x_lr = upsample(x_lr, scale) #interpolate low-res patches with cubic splines. \n",
    "                                     #After this line of code len(x_lr) is equal to len(x)\n",
    "        assert len(x) % scale == 0\n",
    "        assert len(x_lr) == len(x)\n",
    "        assert x.dtype == np.float32\n",
    "        assert x_lr.dtype == np.float32\n",
    "\n",
    "        # generate patches\n",
    "        max_i = len(x) - d + 1\n",
    "        n_patch_of_file = 0\n",
    "        for i in range(0, max_i, s):\n",
    "            i_lr = i\n",
    "            hr_patch = np.array( x[i : i+d] )\n",
    "            lr_patch = np.array( x_lr[i_lr : i_lr+d_lr] )\n",
    "\n",
    "            assert len(hr_patch) == d\n",
    "            assert len(lr_patch) == d_lr\n",
    "\n",
    "            hr_patch.reshape((1,d,1))\n",
    "            lr_patch.reshape((1,d_lr,1))\n",
    "            n_patch_of_file += 1\n",
    "            file_name = '{}_{}_{}.hdf5'.format(ID, j, n_patch_of_file)\n",
    "            h5_file = h5py.File(nested_out_dir + file_name, 'w')\n",
    "            data_set_lr = h5_file.create_dataset('data_lr', lr_patch.shape, np.float32)\n",
    "            data_set_lr[...] = lr_patch\n",
    "            label_set = h5_file.create_dataset('label', hr_patch.shape, np.float32)\n",
    "            label_set[...] = hr_patch\n",
    "            n_files_in_nested_out_dir += 1\n",
    "            file_name_diz[file_name] = {'fold1':fold1, 'nested_fold':nested_out_dir_index}\n",
    "            if n_files_in_nested_out_dir == 500:\n",
    "                n_files_in_nested_out_dir= 0\n",
    "                nested_out_dir_index += 1\n",
    "                nested_out_dir = os.path.join(out_dir, str(nested_out_dir_index), '')\n",
    "                create_dir(nested_out_dir)\n",
    "                n_files_in_nested_out_dir = 0\n",
    "            num_patches += 1\n",
    "            ID_list.append(ID)\n",
    "            \n",
    "    # Devo eliminare dalla cartella i file in eccesso (affinchè il numero totale di file sia multiplo di batch_size).\n",
    "    num_to_keep = int(np.floor(num_patches / batch_size) * batch_size)\n",
    "    to_remove = num_patches - num_to_keep\n",
    "    if to_remove > 0:\n",
    "        files_to_remove = sample(file_name_diz.keys(), to_remove)\n",
    "        for key in files_to_remove:\n",
    "            nested_fold = file_name_diz[key]['nested_fold']\n",
    "            os.remove(os.path.join(out_dir,str(nested_fold),key))\n",
    "            del file_name_diz[key]\n",
    "        print('Sono stati rimossi correttamente {} file'.format(to_remove))\n",
    "    ID_list = ID_list[:num_to_keep]\n",
    "\n",
    "    file = open(out + 'file_list_' + how, 'wb')\n",
    "    pickle.dump(file_name_diz, file)\n",
    "    file.close()\n",
    "    \n",
    "    file = open(out + 'ID_list_patches_' + str(d) + '_' + str(scale), 'wb')\n",
    "    pickle.dump(ID_list, file)\n",
    "    file.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "dksIAU5IG4JU",
    "CyDZ9uRyG4JU"
   ],
   "machine_shape": "hm",
   "name": "Creazione dati di train_validation - multispeaker.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "188ebcbc74594da98c089c5af5f5f1fb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28a9f4a9441d43e39b0d17e982098c99": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5f45b431362c4110bda40d104911010d",
       "IPY_MODEL_66de46012a874a2b91f2a51030e271c5"
      ],
      "layout": "IPY_MODEL_2c3f17f6d6fd493f97e4d70dc2b454cc"
     }
    },
    "2c3f17f6d6fd493f97e4d70dc2b454cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f45b431362c4110bda40d104911010d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e70dbb57f4e84c789507fe1cec23377e",
      "max": 1032,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cb50169f28ef48299e1adfa7857a34b3",
      "value": 1032
     }
    },
    "66de46012a874a2b91f2a51030e271c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_188ebcbc74594da98c089c5af5f5f1fb",
      "placeholder": "​",
      "style": "IPY_MODEL_6d05226406e04aa5aa909fa2e2cfca79",
      "value": " 1032/1032 [00:08&lt;00:00, 116.28it/s]"
     }
    },
    "6d05226406e04aa5aa909fa2e2cfca79": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cb50169f28ef48299e1adfa7857a34b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e70dbb57f4e84c789507fe1cec23377e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
