{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join, splitext, isdir, exists, basename\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_speaker_info(data_root):\n",
    "    speaker_info_path = join(data_root, \"speaker-info.txt\")\n",
    "    if not exists(speaker_info_path):\n",
    "        raise RuntimeError(\n",
    "            \"speaker-info.txt doesn't exist at \\\"{}\\\"\".format(speaker_info_path))\n",
    "    speaker_info = OrderedDict()\n",
    "    filed_names = [\"ID\", \"AGE\", \"GENDER\", \"ACCENTS\", \"REGION\"]\n",
    "    with open(speaker_info_path, \"rb\") as f:\n",
    "        for line in f:\n",
    "            line = line.decode(\"utf-8\")\n",
    "            fields = line.split()\n",
    "            if fields[0] == \"ID\":\n",
    "                continue\n",
    "            assert len(fields) == 4 or len(fields) == 5 or len(fields) == 6\n",
    "            ID = fields[0]\n",
    "            speaker_info[ID] = {}\n",
    "            speaker_info[ID][\"AGE\"] = int(fields[1])\n",
    "            speaker_info[ID][\"GENDER\"] = fields[2]\n",
    "            speaker_info[ID][\"ACCENTS\"] = fields[3]\n",
    "            if len(fields) > 4:\n",
    "                speaker_info[ID][\"REGION\"] = \" \".join(fields[4:])\n",
    "            else:\n",
    "                speaker_info[ID][\"REGION\"] = \"\"\n",
    "    return speaker_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.dirname(os.path.abspath('.'))\n",
    "diz = _parse_speaker_info(os.path.join(ROOT_DIR, 'rawData', 'VCTK-Corpus'))\n",
    "df = pd.DataFrame.from_dict(diz, orient = 'index')\n",
    "df['ID'] = df.index\n",
    "#df.to_csv('df_info.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>ACCENTS</th>\n",
       "      <th>REGION</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>22</td>\n",
       "      <td>F</td>\n",
       "      <td>Scottish</td>\n",
       "      <td>West Dumfries</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>22</td>\n",
       "      <td>F</td>\n",
       "      <td>NorthernIrish</td>\n",
       "      <td>Belfast</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>22</td>\n",
       "      <td>F</td>\n",
       "      <td>Scottish</td>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>22</td>\n",
       "      <td>F</td>\n",
       "      <td>Welsh</td>\n",
       "      <td>Cardiff</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>22</td>\n",
       "      <td>F</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Athlone</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>Canadian</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>SouthAfrican</td>\n",
       "      <td>Cape Town</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AGE GENDER        ACCENTS         REGION   ID\n",
       "234   22      F       Scottish  West Dumfries  234\n",
       "238   22      F  NorthernIrish        Belfast  238\n",
       "249   22      F       Scottish       Aberdeen  249\n",
       "253   22      F          Welsh        Cardiff  253\n",
       "266   22      F          Irish        Athlone  266\n",
       "303   24      F       Canadian        Toronto  303\n",
       "314   26      F   SouthAfrican      Cape Town  314"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_esclusa = ['234','249','266','303','253','238','314']\n",
    "df[df['ID'].isin(lista_esclusa)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample speakers for train-val-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_txt_to_list(txt):\n",
    "    out_list = []\n",
    "    with open(txt) as f:\n",
    "        for line in f:\n",
    "            out_list.append(line.strip())\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtfiles_dir = os.path.join(ROOT_DIR, 'processedData', 'txtfiles')\n",
    "id_list_test = from_txt_to_list(os.path.join(txtfiles_dir, 'test-speakers.txt'))\n",
    "regex = re.compile(r'(p)(\\d*)')\n",
    "id_test = [regex.search(i)[2] for i in id_list_test]\n",
    "\n",
    "df_test = df.loc[id_test]\n",
    "df = df.drop(id_test)\n",
    "df = df.drop('225')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elements_from_dict(df, diz, gender):\n",
    "    out = {}\n",
    "    for accent in diz:\n",
    "        idxs = list(df[(df['GENDER'] == gender)&(df['ACCENTS'] == accent)].head(diz[accent]).index)\n",
    "        for idx in idxs:\n",
    "            id_ = 'p' + str(idx)\n",
    "            out[id_] = {'AGE': df.loc[idx]['AGE'], \n",
    "                       'GENDER': df.loc[idx]['GENDER'],\n",
    "                       'ACCENTS': df.loc[idx]['ACCENTS'],\n",
    "                       'REGION': df.loc[idx]['REGION'],\n",
    "                       'ID': df.loc[idx]['ID']}\n",
    "        df = df.drop(idxs)\n",
    "    return df, pd.DataFrame.from_dict(out, 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sampled_train_val_txt(df, tr_diz_M, tr_diz_F, val_diz_M , val_diz_F):\n",
    "    df, tr_M = get_elements_from_dict(df, tr_diz_M, 'M')\n",
    "    df, tr_F = get_elements_from_dict(df, tr_diz_F, 'F')  \n",
    "    df, val_M = get_elements_from_dict(df, val_diz_M, 'M')\n",
    "    df, val_F = get_elements_from_dict(df, val_diz_F, 'F')\n",
    "    df_tr, df_val = pd.concat([tr_M, tr_F]), pd.concat([val_M, val_F]) \n",
    "    return list(df_tr.index), list(df_val.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English          17\n",
       "American         15\n",
       "Irish             6\n",
       "Canadian          5\n",
       "Scottish          5\n",
       "SouthAfrican      3\n",
       "NorthernIrish     3\n",
       "Welsh             1\n",
       "NewZealand        1\n",
       "Indian            1\n",
       "Name: ACCENTS, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['GENDER'] == 'F'].ACCENTS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English          15\n",
       "Scottish         14\n",
       "American          4\n",
       "Canadian          2\n",
       "Irish             2\n",
       "NorthernIrish     2\n",
       "Australian        1\n",
       "Indian            1\n",
       "Name: ACCENTS, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['GENDER'] == 'M'].ACCENTS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Irish           1\n",
       "Indian          1\n",
       "Canadian        1\n",
       "American        1\n",
       "SouthAfrican    1\n",
       "Australian      1\n",
       "Name: ACCENTS, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['GENDER'] == 'M'].ACCENTS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "American         2\n",
       "NorthernIrish    1\n",
       "Name: ACCENTS, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['GENDER'] == 'F'].ACCENTS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampling_F = {'English': 9, 'American': 3, 'Scottish': 2, \n",
    "                    'Irish': 1, 'Canadian': 1, 'Welsh': 1, 'NorthernIrish': 1, 'SouthAfrican': 1}   \n",
    "train_sampling_M = {'English': 9, 'American': 3, 'Scottish': 3,\n",
    "                    'Irish': 1, 'Canadian': 1, 'Indian': 1, 'Australian': 1}\n",
    "val_sampling_F = {'English': 1, 'NewZealand': 1}\n",
    "val_sampling_M = {'English': 1, 'American': 1}\n",
    "tr_ids, val_ids = create_sampled_train_val_txt(df,\n",
    "                                   tr_diz_M = train_sampling_M,\n",
    "                                   tr_diz_F = train_sampling_F,\n",
    "                                   val_diz_M =val_sampling_M,\n",
    "                                   val_diz_F = val_sampling_F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_list_to_txt(id_list, name, path_to_save):\n",
    "    file = os.path.join(path_to_save, \"{}.txt\".format(name))\n",
    "    with open(file, \"w\") as text_file:\n",
    "        for id_ in id_list:\n",
    "            text_file.write(id_ + '\\n')\n",
    "        text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_list_to_txt(tr_ids, 'train-speakers-sampled', txtfiles_dir)\n",
    "from_list_to_txt(val_ids, 'val-speakers-sampled', txtfiles_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
